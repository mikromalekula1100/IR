\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{amsmath}
\usepackage{float}

\geometry{
    left=30mm,
    right=15mm,
    top=20mm,
    bottom=20mm
}

\lstset{
    basicstyle=\ttfamily\small,
    breaklines=true,
    frame=single,
    backgroundcolor=\color{gray!10},
    keywordstyle=\color{blue},
    commentstyle=\color{green!60!black},
    stringstyle=\color{red}
}

\hypersetup{
    colorlinks=true,
    linkcolor=black,
    urlcolor=blue,
    citecolor=blue
}

\begin{document}

% Титульный лист
\begin{titlepage}
    \centering
    \large
    
    \vspace*{1cm}
    
    \textbf{Московский авиационный институт}\\
    \textbf{(национальный исследовательский университет)}
    
    \vspace{1.5cm}
    
    Факультет информационных технологий и прикладной математики
    
    \vspace{0.5cm}
    
    Кафедра вычислительной математики и программирования
    
    \vspace{3cm}
    
    {\LARGE \textbf{Лабораторные работы по курсу}}\\
    \vspace{0.3cm}
    {\LARGE \textbf{«Информационный поиск»}}
    
    \vfill
    
    \begin{flushright}
        \begin{tabular}{rl}
            Студент: & М.\,В.\,Калуцкий \\
            Преподаватель: & А.\,А.\,Кухтичев \\
            Группа: & М8О-206Б \\
            Дата: & 16.12.2025 \\
            Оценка: & \underline{\hspace{3cm}} \\
            Подпись: & \underline{\hspace{3cm}} \\
        \end{tabular}
    \end{flushright}
    
    \vspace{2cm}
    
    Москва, 2025
\end{titlepage}

\tableofcontents
\newpage

\section{Добыча корпуса документов}

\subsection{Цель работы}

Анализ источников данных, выбор инструментов извлечения текста и получение статистических характеристик корпуса документов для построения поисковой системы.

\subsection{Источники данных}

Для формирования корпуса были выбраны и скачаны примеры документов из двух источников тематики «Информационные технологии»:

\begin{enumerate}
    \item \textbf{Habr.com} — профессиональное сообщество IT-специалистов.
    
    \textit{Характеристика:} Тексты содержат большое количество профессионального сленга, англицизмов и фрагментов программного кода.
    
    \item \textbf{Wikipedia.org (Ru)} — свободная энциклопедия (категория «Компьютерные науки»).
    
    \textit{Характеристика:} Научный/энциклопедический стиль, строгая структура, наличие плотной сети перекрестных ссылок.
\end{enumerate}

\subsection{Характеристика документов}

В ходе анализа «сырого» HTML-кода выявлено:

\begin{itemize}
    \item \textbf{Формат:} HTML5, кодировка UTF-8.
    \item \textbf{Структура текста:} Основной контент заключен в теги \texttt{<p>} (параграфы), \texttt{<h1>}-\texttt{<h6>} (заголовки). Списки оформлены через \texttt{<ul>}/\texttt{<ol>}.
\end{itemize}

\textbf{Особенности разметки:}

\begin{itemize}
    \item На Хабре код обернут в теги \texttt{<pre><code ...>}. Это важно учитывать при индексации (либо исключать, либо индексировать специфически).
    \item В Википедии множество ссылок \texttt{<a>}, скрытых сносок и формул (LaTeX/MathML).
    \item \textbf{Мета-информация:} Присутствует в тегах \texttt{<meta>} (author, description, keywords). Также используется разметка Open Graph (\texttt{og:title}, \texttt{og:image}), которая может быть полезна для формирования сниппетов в выдаче.
\end{itemize}

\subsection{Выделение текста}

Для очистки документов от HTML-тегов был разработан скрипт на языке Python с использованием библиотеки \texttt{BeautifulSoup4}.

\textbf{Метод:} Удаление тегов \texttt{<script>}, \texttt{<style>}, \texttt{<nav>}, \texttt{<footer>}, \texttt{<header>}, \texttt{<aside>} и извлечение текстового содержимого из оставшегося дерева DOM.

\textbf{Результат:} Получен чистый текст, пригодный для токенизации.

\subsection{Анализ существующих поисковиков}

Был проведен анализ возможностей поиска по выбранным ресурсам с использованием Google (оператор \texttt{site:}).

\textbf{Пример запроса 1:} \texttt{site:habr.com "распределенные системы"}

\textit{Результат:} Google находит релевантные статьи.

\textit{Недостаток:} В выдачу попадают комментарии пользователей, которые могут быть нерелевантны теме статьи, а также профили пользователей и дубликаты.

\textbf{Пример запроса 2:} \texttt{site:ru.wikipedia.org "булев поиск"}

\textit{Результат:} Найдена основная статья и множество смежных.

\textit{Недостаток:} В выдачу попадают служебные страницы («Обсуждение:», «История правок», «Википедия:Форум»), которые являются шумом для информационного поиска.

\textbf{Общая проблема:} Отсутствие возможности гибкого управления булевой логикой (например, найти документы, где есть "Linux", но строго НЕТ "Windows") в рамках, ограниченных конкретным списком документов пользователя.

\subsection{Статистическая информация о корпусе}

Были загружены и проанализированы 6 контрольных документов (по 3 с каждого источника).

\begin{table}[h]
\centering
\begin{tabular}{@{}ll@{}}
\toprule
\textbf{Параметр} & \textbf{Значение} \\ \midrule
Количество примеров & 6 \\
Размер примеров «сырых» документов (HTML) & От 271 КБ до 547 КБ \\
Средний размер «сырого» документа & 286\,994 байт \\
Средний объем выделенного текста & 36\,647 байт \\
Отношение текста к мусору (Ratio) & 12.77\% \\ \bottomrule
\end{tabular}
\caption{Статистические характеристики корпуса документов}
\end{table}

\subsection{Вывод}

\begin{itemize}
    \item Выбранные источники (Habr, Wikipedia) удовлетворяют требованиям к корпусу: они имеют единую тематику, достаточный объем текста и сложную внутреннюю структуру.
    \item Большой объем «мусора» (скрипты, стили) — решено фильтрацией тегов. Наличие программного кода, который может засорять индекс (фигурные скобки, спецсимволы).
    \item Отношение полезного текста к общему объему (Ratio 12\%) показывает, что хранение сырых данных требует в 8 раз больше места, чем чистого текста, однако это необходимо для сохранения целостности и возможности переиндексации.
\end{itemize}

\newpage

\section{Поисковый робот}

\subsection{Цель работы}

Разработать автоматический сборщик документов (краулер), который обходит веб-страницы по ссылкам, скачивает их HTML-содержимое и сохраняет в базу данных.

\textbf{Ключевые требования:}

\begin{itemize}
    \item Конфигурация через YAML-файл.
    \item Поддержка остановки и возобновления работы (Resume capability).
    \item Сохранение «сырых» данных для последующей обработки.
\end{itemize}

\subsection{Метод решения}

Выбран язык Python, так как он обладает развитыми инструментами для работы с сетью (\texttt{requests}) и парсинга HTML (\texttt{BeautifulSoup4}).

В качестве хранилища выбрана встраиваемая СУБД \textbf{SQLite}. Это позволяет хранить весь корпус в одном файле \texttt{crawler\_data.db} без необходимости разворачивания серверных БД (PostgreSQL/MongoDB), что упрощает перенос проекта.

\textbf{Архитектура системы:} модуль инициализации читает \texttt{config.yaml}, создает таблицы \texttt{documents} и \texttt{queue} (если их нет), добавляет начальные ссылки (\texttt{seed\_urls}).

\textbf{Модуль обкачки (Worker):}

\begin{itemize}
    \item Берет URL из очереди со статусом \texttt{new}.
    \item Выполняет HTTP GET запрос.
    \item При коде ответа 200 сохраняет контент.
    \item Извлекает гиперссылки, нормализует их (превращает относительные \texttt{/wiki/...} в абсолютные \texttt{https://ru.wikipedia.org/wiki/...}) и добавляет в очередь.
\end{itemize}

\subsection{Конфигурация}

Настройки вынесены в файл \texttt{config.yaml} для гибкости управления процессом без перекомпиляции кода:

\begin{lstlisting}[language=yaml]
db:
  path: "crawler_data.db"

logic:
  request_delay: 0.01
  max_docs: 32000
  
  seed_urls:
    - "https://habr.com/ru/all/"
    - "https://ru.wikipedia.org/wiki/Категория:Программное_обеспечение"
    - "https://ru.wikipedia.org/wiki/Категория:Компьютерные_науки"

  allowed_domains:
    - "habr.com"
    - "ru.wikipedia.org"
\end{lstlisting}

\subsection{Журнал выполнения задания}

В процессе реализации возникли следующие проблемы:

\begin{enumerate}
    \item \textbf{Робот попадал в «ловушки»} — бесконечные календарные ссылки или служебные страницы (версии для печати).
    
    \textit{Решение:} Внедрена фильтрация URL. Игнорируются ссылки, содержащие \texttt{\#} (якоря), \texttt{?} (параметры запроса для служебных страниц), а также ссылки на файлы изображений и PDF.
    
    \item \textbf{Блокировка со стороны серверов (403 Forbidden).}
    
    \textit{Решение:} Добавлен заголовок \texttt{User-Agent: Mozilla/5.0...} и искусственная задержка \texttt{time.sleep} между запросами.
    
    \item \textbf{Кодировка данных.}
    
    \textit{Решение:} Принудительное использование кодировки UTF-8 при записи в БД и чтении.
\end{enumerate}

\subsection{План тестирования}

Для проверки корректности работы робота были проведены следующие тесты:

\begin{longtable}{@{}clp{5cm}p{5cm}@{}}
\toprule
\textbf{№} & \textbf{Сценарий} & \textbf{Ожидаемый результат} & \textbf{Фактический результат} \\ \midrule
\endfirsthead
\toprule
\textbf{№} & \textbf{Сценарий} & \textbf{Ожидаемый результат} & \textbf{Фактический результат} \\ \midrule
\endhead
1 & Базовый сбор & Запуск робота с пустым documents. Робот начинает скачивать статьи и наполнять таблицу. & Успешно. Таблицы созданы, данные появились. \\
2 & Фильтрация доменов & В статьях есть ссылки на Youtube и Facebook. Они не должны попадать в очередь. & Успешно. В таблице queue только ссылки Habr/Wiki. \\
3 & Resume (Возобновление) & Принудительная остановка (Ctrl+C) и повторный запуск. Робот не должен качать заново уже скачанное. & Успешно. Робот продолжил с того места, где остановился. \\
4 & Обработка 404 & Попытка скачивания несуществующей страницы. & Успешно. Робот вывел ошибку в лог и перешел к следующей ссылке. \\ \bottomrule
\caption{Результаты тестирования поискового робота}
\end{longtable}

\subsection{Результаты работы}

\begin{itemize}
    \item \textbf{Собрано документов:} > 30\,000 шт. (процесс продолжается).
    \item \textbf{Объем базы данных:} $\sim$1.2 ГБ (для первых 3500 документов).
    \item \textbf{Средняя скорость:} $\sim$3--5 документов в секунду (ограничена искусственной задержкой).
\end{itemize}

\subsection{Вывод}

Разработанный поисковый робот справляется с задачей автоматического сбора корпуса документов. Реализация на Python с использованием SQLite обеспечивает надежность (ACID-транзакции при записи) и удобство дальнейшей обработки данных на C++. Механизм очереди в БД позволяет прерывать процесс обкачки без потери прогресса, что критично при сборе больших объемов данных.

\newpage

\section{Токенизация}

\subsection{Цель работы}

Реализовать эффективный алгоритм выделения чистого текста из HTML-документов и разбиения его на токены (слова). Провести анализ производительности и качества выделения терминов.

\subsection{Правила токенизации}

Для обработки текста выработаны следующие правила:

\begin{enumerate}
    \item \textbf{Очистка от тегов:} Любая последовательность символов между \texttt{<} и \texttt{>} удаляется. Тег заменяется на пробел, чтобы предотвратить склеивание слов (например, \texttt{<div>Word1</div><div>Word2</div>} $\rightarrow$ \texttt{Word1 Word2}).
    
    \item \textbf{Разделители:} К разделителям отнесены:
    \begin{itemize}
        \item Пробельные символы (пробел, табуляция, перенос строки, ASCII коды $\leq$ 32).
        \item Знаки препинания: \texttt{. , ! ? : ; " ' ( ) [ ] -}.
    \end{itemize}
    
    \item \textbf{Допустимые символы:} Все остальные символы (буквы любых алфавитов, цифры, \texttt{\_}, \texttt{@}, \texttt{\#}) считаются частью токена.
    
    \item \textbf{Нормализация:} Латинские символы приводятся к нижнему регистру (A--Z $\rightarrow$ a--z). Кириллица оставляется без изменений (в текущей реализации на C++ без ICU).
\end{enumerate}

\subsection{Анализ метода}

\textbf{Достоинства:}

\begin{itemize}
    \item \textbf{Экстремальная производительность:} Использование C++ и прямого прохода по памяти (без регулярных выражений) обеспечивает скорость >40 МБ/с.
    \item \textbf{Предсказуемость:} Алгоритм детерминирован и не зависит от внешних словарей.
\end{itemize}

\textbf{Недостатки и примеры ошибок:}

\begin{itemize}
    \item \textbf{Склеивание URL:} Ссылки вида \texttt{https://habr.com/ru/post} воспринимаются как один длинный токен, так как символ \texttt{/} не был включен в список разделителей.
    
    \textit{Исправление:} Добавить \texttt{/} в список разделителей.
    
    \item \textbf{Мусорные символы:} Токены вида \texttt{\{} (фигурная скобка) или \texttt{var\_name} часто встречаются в коде.
    
    \textit{Исправление:} Игнорировать токены, состоящие только из спецсимволов, или ввести эвристику «токен должен содержать хотя бы одну букву».
    
    \item \textbf{Некорректный регистр:} Слова «Привет» и «привет» считаются разными токенами, так как упрощенная функция \texttt{tolower} работает только с ASCII.
\end{itemize}

\subsection{Результаты измерений}

\begin{table}[h]
\centering
\begin{tabular}{@{}ll@{}}
\toprule
\textbf{Параметр} & \textbf{Значение} \\ \midrule
Количество токенов & 41\,589\,970 \\
Средняя длина токена & 11.13 символов \\
Время выполнения & 12.24 сек \\
Объем чистого текста & 529.5 МБ \\
Скорость токенизации & 43.2 МБ/сек (43\,247 КБ/с) \\ \bottomrule
\end{tabular}
\caption{Результаты токенизации корпуса}
\end{table}

\subsection{Анализ производительности}

\textbf{Зависимость времени от данных:} Зависимость линейная $O(N)$, где $N$ — объем текста. Алгоритм совершает один проход по каждому байту входных данных, не выполняя сложных возвратов или вложенных циклов.

\textbf{Оценка оптимальности:} Скорость 43 МБ/с является высокой для работы с БД SQLite (узким местом является не процессор, а чтение с диска и декодирование строк из БД).

\subsection{Способы ускорения}

\begin{itemize}
    \item \textbf{Многопоточность:} Разнести чтение из БД и парсинг текста по разным потокам (паттерн Producer-Consumer). Пока один поток ждет диск, второй токенизирует.
    
    \item \textbf{Memory Mapping:} Использовать отображение файла БД в память (\texttt{mmap}) для исключения копирования данных при чтении. Это могло бы ускорить процесс в 2--3 раза.
\end{itemize}

\newpage

\section{Закон Ципфа}

\subsection{Цель работы}

Построить частотный словарь корпуса, распределить слова по рангам и проверить выполнение закона Ципфа, который гласит:
$$\text{Frequency} \approx \frac{\text{Constant}}{\text{Rank}}$$

\subsection{Реализация}

На базе токенизатора написана программа \texttt{frequency.cpp}, которая:

\begin{itemize}
    \item Считывает документы из SQLite.
    \item Разбивает текст на токены.
    \item Использует хэш-таблицу (или красно-черное дерево \texttt{std::map}) для подсчета количества вхождений каждого уникального слова.
    \item Сортирует список слов по убыванию частоты.
    \item Выгружает результат в \texttt{freq\_data.csv}.
\end{itemize}

График построен с помощью скрипта на Python (\texttt{matplotlib}).

\subsection{Результаты}

\textbf{Самый частотный токен:} \texttt{\{} (фигурная скобка).

\textbf{Причина:} Корпус документов (Habr, Wikipedia IT) содержит большое количество фрагментов программного кода (Java, C++, JS), которые не были отфильтрованы на этапе токенизации. Это демонстрирует важность предварительной обработки специфических текстов.

\textbf{Следование закону:} График в логарифмическом масштабе (Log-Log) демонстрирует линейное убывание, что соответствует закону Ципфа. Наблюдается небольшое отклонение в верхней части («хвосте») из-за специфических символов кода и в нижней части (редкие слова).

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{zipf_graph.pdf}  % PDF обычно лучше для LaTeX
    \caption{График закона Ципфа для корпуса документов}
    \label{fig:zipf}
\end{figure}

\subsection{Вывод}

Корпус данных подчиняется статистическим законам естественного языка (с поправкой на компьютерный сленг и код).

\newpage

\section{Стемминг}

\subsection{Цель работы}

Реализовать компонент морфологической нормализации (стемминг) для приведения словоформ к единой основе. Оценить влияние стемминга на показатели качества поиска (Recall и Precision).

\subsection{Метод решения}

Поскольку использование готовых NLP-библиотек (NLTK, Snowball, mystem) запрещено, был реализован собственный упрощенный алгоритм \textbf{Suffix Stripping} (отсечение суффиксов). Стемминг внедрен на этапе индексации (для слов в документах) и на этапе поиска (для слов запроса).

\textbf{Алгоритм:}

\begin{enumerate}
    \item \textbf{Проверка длины:} Слова длиной менее 4 байт (в UTF-8) игнорируются, чтобы избежать порчи коротких слов (предлогов, союзов, аббревиатур типа IT, OS).
    
    \item \textbf{Поиск суффикса:} Реализован перебор списка наиболее частотных окончаний:
    \begin{itemize}
        \item Русский: \texttt{-ыми, -ого, -ему, -ая, -ый, -ий...} (проверка идет побайтово для UTF-8 строк).
        \item Английский: \texttt{-ational, -ing, -ed, -ly, -s...}
    \end{itemize}
    
    \item \textbf{Отсечение:} Если слово заканчивается на суффикс, он удаляется. Происходит только одно отсечение (не итеративное, в отличие от стеммера Портера, что быстрее, но грубее).
\end{enumerate}

\subsection{Результаты тестирования алгоритма}

Тесты (\texttt{stemmer\_test}) подтвердили корректность работы с байтовыми строками:

\begin{itemize}
    \item \texttt{computers} $\rightarrow$ \texttt{computer} (Корректно)
    \item \texttt{computing} $\rightarrow$ \texttt{comput} (Корректно, основа совпадает)
    \item \texttt{красного} $\rightarrow$ \texttt{красн} (Корректно обрезано 4 байта окончания)
    \item \texttt{программирование} $\rightarrow$ \texttt{программировани}
\end{itemize}

\subsection{Анализ влияния на качество поиска}

\textbf{Улучшение (Рост Recall):} Для большинства запросов качество поиска выросло. Например, по запросу [\textit{красный}] теперь находятся документы, содержащие слова «красного», «красному», «красные». Без стемминга мы бы потеряли до 60\% релевантных документов, где слово стоит в косвенном падеже.

\textbf{Ухудшение (Падение Precision) и анализ проблем:}

\begin{enumerate}
    \item \textbf{Проблема омонимии основ:}
    \begin{itemize}
        \item Слова «банк» (финансы) и «банка» (сосуд) могут быть обрезаны до одной основы \textit{банк}, если алгоритм решит, что \texttt{-а} — это окончание. В результате по запросу о финансовых банках в выдачу попадет мусор про стеклянные банки.
        \item Английский пример: \textit{universal} (универсальный) и \textit{university} (университет). Если обрезать суффиксы агрессивно, они могут склеиться в \textit{univers}, смешивая разные понятия.
    \end{itemize}
    
    \item \textbf{Изменение смысла:}
    \begin{itemize}
        \item Стеммер может обрезать слово «летел» до «лет» (думая, что \texttt{-ел} суффикс), смешивая его со словом «лето» (год).
    \end{itemize}
\end{enumerate}

\textbf{Чтобы исправить эти проблемы, не ухудшая поиск по другим запросам, можно:}

\begin{itemize}
    \item \textbf{Использовать словари исключений:} Запретить стемминг для списка слов, где изменение окончания меняет смысл (например, \textit{university}).
    
    \item \textbf{Гибридный поиск:} Искать сначала по точному совпадению (давая таким документам больший вес/бонус), и только затем добавлять результаты по стеммам. Это поднимет Precision, сохранив высокий Recall.
\end{itemize}

\newpage

\section{Булев индекс}

\subsection{Цель работы}

Разработать бинарный формат индекса и программу-индексатор, которая преобразует собранный корпус документов в поисковую структуру (Обратный индекс / Inverted Index) без использования готовых СУБД.

\subsection{Формат данных}

Разработан собственный бинарный формат, оптимизированный для последовательного чтения (\texttt{mmap}). Индекс разделен на два файла:

\begin{itemize}
    \item \textbf{\texttt{docs.bin} (Прямой индекс):} Связывает ID с URL.
    \begin{itemize}
        \item Структура записи: [\texttt{DocID} (4 байта)] [\texttt{UrlLen} (8 байт)] [\texttt{URL} (\texttt{UrlLen} байт)].
    \end{itemize}
    
    \item \textbf{\texttt{index.bin} (Обратный индекс):} Основной словарь и списки вхождения.
    \begin{itemize}
        \item Структура записи: [\texttt{TermLen} (4 байта)] [\texttt{TermString} (\texttt{TermLen} байт)] [\texttt{DocCount} (4 байта)] [\texttt{DocID\_1} (4 байта)] ... [\texttt{DocID\_N} (4 байта)].
    \end{itemize}
\end{itemize}

\subsection{Реализация структур данных и алгоритмов}

\textbf{Внутреннее представление:} Для накопления индекса в оперативной памяти использована самописная \textbf{Хэш-таблица} с разрешением коллизий методом цепочек (Linked List). Размер таблицы — 50\,021 (простое число).

\textbf{Токенизация:} Термы приводятся к нижнему регистру и проходят стемминг (алгоритм из ЛР5).

\textbf{Метод сортировки:}

\begin{itemize}
    \item Использована естественная сортировка при вставке. Так как индексатор обрабатывает документы последовательно (DocID: 1, 2, 3...), новые ID всегда добавляются в конец списка (Tail) для каждого терма.
    
    \item \textbf{Достоинство:} Вставка за $O(1)$. Постинг-листы автоматически получаются отсортированными, что позволяет в дальнейшем (ЛР7) выполнять булевы операции пересечения за линейное время $O(N)$.
    
    \item \textbf{Недостаток:} Неудобно обновлять индекс (удалять/изменять старые документы), требуется полная перестройка.
\end{itemize}

\subsection{Результаты измерений}

\begin{itemize}
    \item \textbf{Количество обработанных документов:} $\sim$5000.
    \item \textbf{Количество уникальных термов:} 845\,624.
    \item \textbf{Анализ средней длины терма:}
    \begin{itemize}
        \item В ЛР3 (Токенизация): Средняя длина была 11.13.
        \item В ЛР6 (Индекс): Средняя длина уменьшилась (примерно до 9--10).
        \item \textbf{Причина отличий:} применяется стемминг, который отсекает суффиксы и окончания (\texttt{computers} $\rightarrow$ \texttt{computer}, \texttt{красного} $\rightarrow$ \texttt{красн}), делая слова короче. Однако наличие «мусорных» длинных токенов (URL, код) в словаре все еще удерживает среднее значение достаточно высоким.
    \end{itemize}
    \item \textbf{Скорость индексации:} $\sim$400 документов в секунду (ограничено скоростью чтения SQLite и выводом в консоль).
\end{itemize}

\subsection{Анализ оптимальности и масштабируемости}

\textbf{Оценка:} Текущая реализация (In-Memory Hash Table) является самой быстрой для небольших объемов, так как исключает дисковые операции ввода-вывода (IO) при построении.

\textbf{Ограничение:} Объем физической оперативной памяти (RAM).

\textbf{Масштабируемость:}

\begin{itemize}
    \item $\times$10 (50k документов): Система справится, потребление RAM вырастет до $\sim$500--800 МБ.
    \item $\times$100 (500k документов): Риск исчерпания памяти (Out of Memory), система начнет использовать Swap и критически замедлится.
    \item $\times$1000 (5 млн документов): Индексация в памяти невозможна.
\end{itemize}

\textbf{Решение для больших объемов:}

\begin{itemize}
    \item Переход на алгоритм \textbf{SPIMI} (Single-Pass In-Memory Indexing).
    \item Накапливать индекс порциями по 100 МБ.
    \item Сбрасывать отсортированные блоки на диск.
    \item В конце выполнять слияние (K-way Merge) блоков в итоговый \texttt{index.bin}.
\end{itemize}

\newpage

\section{Булев поиск и реализация интерфейса}

\subsection{Цель работы}

Реализовать поисковый движок (Search Engine), выполняющий булевы запросы по бинарному индексу.

\textbf{Требования к синтаксису:}

\begin{itemize}
    \item Операторы: \texttt{\&\&} (И), \texttt{||} (ИЛИ), \texttt{!} (НЕТ);
    \item Поддержка приоритета операций (скобки);
    \item Реализация двух интерфейсов: CLI (командная строка) для тестов и Web (HTML-форма) для пользователей.
\end{itemize}

\subsection{Метод решения}

Система построена по двухуровневой архитектуре:

\subsubsection{A) Backend (C++): Программа \texttt{searcher}}

Ядро поиска загружает файлы \texttt{index.bin} и \texttt{docs.bin} в оперативную память (RAM) при старте.

\begin{itemize}
    \item \textbf{Парсинг запроса:} Реализован лексический анализатор, который разбивает строку запроса на поток токенов. Для обработки слов используется тот же стеммер, что и в ЛР5 (нормализация запроса).
    
    \item \textbf{Выполнение операций:} Благодаря тому, что в ЛР6 списки документов (Posting Lists) были отсортированы, булевы операции выполняются за линейное время $O(N+M)$ с помощью алгоритмов STL:
    \begin{itemize}
        \item \texttt{\&\&}: \texttt{std::set\_intersection} (пересечение);
        \item \texttt{||}: \texttt{std::set\_union} (объединение);
        \item \texttt{!}: \texttt{std::set\_difference} (разность множества всех документов и множества терма).
    \end{itemize}
\end{itemize}

\subsubsection{B) Frontend (Python): Скрипт \texttt{server.py}}

Легковесный веб-сервер на базе \texttt{http.server}.

\begin{itemize}
    \item Принимает запрос из браузера.
    \item Запускает C++ утилиту через \texttt{subprocess}.
    \item Парсит вывод консоли и генерирует HTML-страницу с кликабельными ссылками.
\end{itemize}

\subsection{Методика тестирования корректности}

Для верификации результатов использовался метод перекрестной проверки:

\begin{enumerate}
    \item \textbf{Проверка оператора AND:} Выполнялись запросы A и B по отдельности. Убедились, что список документов для \texttt{A \&\& B} является подмножеством обоих одиночных результатов.
    
    \item \textbf{Проверка оператора NOT:} Запрос \texttt{!java}. Выборочная ручная проверка показала, что в найденных документах слово «java» отсутствует.
    
    \item \textbf{Визуальная валидация:} Через веб-интерфейс осуществлялся переход по ссылкам для проверки релевантности контента.
\end{enumerate}

\subsection{Результаты и производительность}

Тестирование проводилось на индексе из $\sim$5000 документов.

\textbf{Скорость выполнения:}

\begin{itemize}
    \item Поиск выполняется мгновенно (< 1 мс) даже для сложных запросов.
    \item \textbf{Причина:} Весь индекс находится в RAM, отсутствуют дисковые операции (Disk I/O) в момент поиска.
\end{itemize}

\textbf{Анализ «сложных» запросов:}

В ТЗ требовалось найти запросы, вызывающие длительную работу. В текущей архитектуре (In-Memory Index) таких запросов практически нет. Задержка может возникнуть только при запросе очень распространенных слов (стоп-слов) в комбинации с оператором \texttt{||} (OR), когда результирующий список содержит почти все документы базы (например, \texttt{и || в || на}), так как основное время тратится на вывод 5000 ссылок в консоль, а не на поиск.

\subsection{Примеры запросов}

\begin{enumerate}
    \item \textbf{Запрос:} \texttt{компьютер}
    \begin{itemize}
        \item Найдено: 699 док.
        \item Статус: Успешно. Выдача релевантна.
    \end{itemize}
    
    \item \textbf{Запрос:} \texttt{linux \&\& python}
    \begin{itemize}
        \item Найдено: 4509 док.
        \item Анализ: Аномально большой результат вызван особенностями верстки сайта Habr (сквозные блоки навигации в футере, которые попали в индекс). Требуется улучшение очистки HTML в ЛР1.
    \end{itemize}
    
    \item \textbf{Запрос:} \texttt{!java}
    \begin{itemize}
        \item Найдено: 4512 док.
        \item Статус: Успешно. Из 5000 документов отсеяно $\sim$500, содержащих слово Java.
    \end{itemize}
\end{enumerate}

\subsection{Вывод}

Реализована полнофункциональная поисковая система. Использование бинарного индекса и булевой алгебры на сортированных списках обеспечило максимальную производительность поиска.

\end{document}
